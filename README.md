# ğŸ¥ Healthcare Patient Analytics Pipeline

An end-to-end Azure data pipeline built on **Medallion Architecture (Bronze â†’ Silver â†’ Gold)** to process real hospital patient records and generate analytics-ready insights.

---

## ğŸ”§ Tech Stack
- **Azure Data Factory** â€” Pipeline orchestration & parameterized Copy Activity
- **Azure Databricks (PySpark)** â€” Data transformation & incremental loading
- **ADLS Gen2** â€” Data lake storage across all medallion layers
- **Azure Key Vault** â€” Secure secret management (no hardcoded credentials)

---

## ğŸ—ï¸ What I Built

### Pipeline Flow
```
Raw CSV (Kaggle)
     â†“  ADF Copy Activity (CSV â†’ Parquet + column mapping)
Silver Layer (cleaned Parquet)
     â†“  Databricks Notebook (PySpark transformations)
Gold Layer (3 analytics tables)
```

### Medallion Layers
| Layer | Format | Description |
|---|---|---|
| Bronze | CSV | Raw Kaggle dataset (55,500 rows, 8.4MB) |
| Silver | Parquet | Cleaned, typed, deduplicated (4.17MB) |
| Gold | Parquet | 3 aggregated analytics tables |

### Gold Tables
| Table | Insight |
|---|---|
| `readmission_rates` | Admissions by condition & type |
| `diagnosis_trends` | Cases by age group & year |
| `avg_treatment_costs` | Costs by condition, medication & insurer |

---

## âš™ï¸ Key Features
- **Parameterized ADF pipeline** â€” dynamic file paths, reusable across environments
- **Incremental loading** â€” watermark-based pattern processes only new records each run
- **Key Vault integration** â€” secrets fetched securely via Databricks secret scope
- **Managed Identity** â€” ADF authenticates to ADLS without stored credentials

---

## ğŸ“Š Dataset
[Hospital Patient Records â€” Kaggle](https://www.kaggle.com/datasets/prasad22/healthcare-dataset)
55,500 rows | 15 columns | Patient admissions from 2019â€“2025

---


